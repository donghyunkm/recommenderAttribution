[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Recommender System Attribution with TracIn",
    "section": "",
    "text": "Introduction\nRecommender systems use machine learning models to find items (eg. movies, songs) that a user may like.\nData available to recommender systems include past user-item interactions, similarity of user behavior, item features, user’s context, among other available information. We focus on sequential recommender models, which predict future items that a user may interact with based on that user’s interaction history.\nThe performance of recommender systems has significant financial implications.\nThe goal of our study is to examine why certain recommendations are bad and find methods to improve them.\nBefore this project was put on hold, I developed methods to identify “bad” training data. Once identified, a new model was trained with the “bad” data removed/corrected.\nExamples of “bad” data include users erroenously clicking on unrelated items and users missing relevant items. Because we assume that all user-item interactions reflect a user’s preference, “bad” data significantly affects the quality of recommendations.\n\n\nSequential recommendation model\nWe use a fairly simple sequential recommender system based on a LSTM (Long Short-Term Memory) model.\nFirst, all items are mapped to an embedding vector. Fixed length sequences of embedding vectors are fed into a LSTM model. The last timestep index of the LSTM’s output is then fed into a fully connected layer to predict the next item a user may interact with.\n\n\nLong Short-Term Memory\nLong Short-Term Memory is a recurrent neural nework composed of a memory cell, input gate, output gate, and forget gate (Hochreiter and Schmidhuber 1997). The memory cell remembers information over long sequences. The input gate decides how much of a new input should be remembered, the output gate decides how much of the information in the memory cell should influence the output, and the forget gate decides how much information to discard from the memory cell.\n\n\nTracIn\nWe use TracIn (Pruthi et al. 2020) to identify “bad” training data.\nTracIn computes the influence of a training instance on a prediction made by the model. The method estimates the change in test loss when the training instance of interest is used to update model weights.\nTraining data that reduce loss are “proponents” and training data that increase loss are “opponents.”\nUsing TracIn, “bad” data is equivalent to “opponents.”\nThe idealized notion of influence of a training instance on a prediction is defined as the total reduction in loss on test data \\(z'\\) whenever training data \\(z\\) is used.\n\\[\nTracInIdeal(z, z') = \\sum_{t: z_t = z} \\ell(w_t, z') - \\ell(w_{t+1}, z')\n\\]\nThe authors provide a practical implementation, using saved checkpoints.\n\\[\nTracInCP(z, z') = \\sum_{i = 1}^k \\eta \\nabla \\ell(w_{t_i}, z) \\cdot \\nabla \\ell(w_{t_i}, z')\n\\]\nThis formula is derived using a first order approximation \\(\\ell(w_{t+1}, z') = \\ell(w_t, z') + \\nabla \\ell(w_t, z') \\cdot (w_{t+1} - w_t) + O(||w_{t+1} - w_t||^2)\\) and change in parameter formula \\(w_{t+1} - w_t = -\\eta \\nabla \\ell(w_t, z_t)\\).\n\n\nData\nWe use a subset of the Movielens 1M Dataset for experiments (Maxwell 2015): around 100000 training sequences. The dataset contains 1 million ratings from 6000 users on 4000 movies with timestamps for each rating.\n\n\nTracIn applied to Movielens\nWe apply TracIn to Movielens and find proponents/opponents for several well-known movies.\n\n\n\n\n\n\n\n\nTest item\nTop 2 proponents\nTop 2 opponents\n\n\n\n\nReturn of the Jedi (1983)\nStar Wars (1977), Toy Story (1995)\nPretty Woman (1990), Mrs. Doubtfire (1993)\n\n\nStar Trek III: The Search for Spock (1984)\nStar Trek VI: The Undiscovered Country (1991), Speed (1994)\nSense and Sensibility (1995), Amadeus (1984)\n\n\nL.A. Confidential (1997)\nEnglish Patient, The (1996), Contact (1997)\nTwister (1996), Die Hard 2 (1990)\n\n\nCitizen Kane (1941)\nAmadeus (1984), Casablanca (1942)\nBatman Returns (1992), Batman Forever (1995)\n\n\nTop Gun (1986)\nJurassic Park (1993), Speed (1994)\nEnglish Patient, The (1996), Sense and Sensibility (1995)\n\n\nJaws (1975)\nAlien (1979), Schindler’s List (1993)\nLiar Liar (1997), Boogie Nights (1997)\n\n\nG.I. Jane (1997)\nAir Force One (1997), Contact (1997)\nFargo (1996), Return of the Jedi (1983)\n\n\n\nFrom a quick glimpse, these results seem to make sense: eg. “Star Wars” positively influencing predictions for “Return of the Jedi.”\n\n\nTraining new model with opponents removed\nWith opponents identified, we train a new model with 500 opponent training sequences removed.\n\n\n\nTrain data\nTest MRR\nTest Recall@10\n\n\n\n\nOriginal\n0.0238\n0.0452\n\n\n500 opponents removd\n0.0264\n0.0514\n\n\n\nWe see that test performance (test data is kept constant for both settings) improves once opponents are removed.\n\n\nFuture work\nI am interested in applying TracIn (or other similar methods) to the medical domain. TracIn could be used to identify “opponent” medical images for computer vision tasks in the medical domain.\n\n\n\n\n\nReferences\n\nHochreiter, Sepp, and Jürgen Schmidhuber. 1997. “Long Short-Term Memory.” Neural Computation 9 (8): 1735–80.\n\n\nMaxwell, H. 2015. “A, k.: The MovieLens Datasets.” ACM Transactions on Interactive Intelligent Systems (TiiS).\n\n\nPruthi, Garima, Frederick Liu, Satyen Kale, and Mukund Sundararajan. 2020. “Estimating Training Data Influence by Tracing Gradient Descent.” Advances in Neural Information Processing Systems 33: 19920–30."
  }
]